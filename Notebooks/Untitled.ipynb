{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import nltk\n",
    "import pickle\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#stop_words =  list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "stop_words.extend(['game','pokemon','pokémon'])\n",
    "\n",
    "# for word in stop_words:\n",
    "#     if word in stop_words: \n",
    "#         continue\n",
    "#     else: stop_words.append(word)\n",
    "\n",
    "# for word in stop_words:\n",
    "#     no_punct = remove_punctuation(word)\n",
    "#     if no_punct not in stop_words: \n",
    "#         stop_words.append(no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'game',\n",
       " 'pokemon',\n",
       " 'pokémon']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pokemon.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)\n",
    "\n",
    "df['rating'] = df['rating'].astype(int)\n",
    "\n",
    "def sentiment(x):\n",
    "    if x > 7:\n",
    "        return 'positive'\n",
    "    if x < 5:\n",
    "        return 'negative'\n",
    "    else: return 'mixed'\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(lambda x:sentiment(x))\n",
    "\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df.drop_duplicates(subset='name', keep = 'first', inplace = True)\n",
    "\n",
    "def language_detection(x): \n",
    "    result = detect(x)\n",
    "    if result == 'en':\n",
    "        return x \n",
    "    else: return np.NaN \n",
    "    \n",
    "df['review'] = df['review'].apply(lambda x:language_detection(x))\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "def remove_r(x):\n",
    "    return x.replace('\\r','')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:remove_r(x))  \n",
    "\n",
    "def strip_whitespace(x):\n",
    "    return x.strip()\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:strip_whitespace(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = df[df['sentiment'] == 'negative'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ChocolateCrane</td>\n",
       "      <td>Nov 18, 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>Let us address the elephant in the room first....</td>\n",
       "      <td>sword</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>firstlovezombie</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>I really love Pokemon, which is why I'm so cri...</td>\n",
       "      <td>sword</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FilthyActs88</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Pokémon sword and shield is a game of pure med...</td>\n",
       "      <td>sword</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Ninjasuite</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>This is what happen if a company realize that ...</td>\n",
       "      <td>sword</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>JustrzBustrz</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>It’s an amazing feat how soulless this game fe...</td>\n",
       "      <td>sword</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2889</td>\n",
       "      <td>Gonz04</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>This game is so disappointing, I literally end...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2891</td>\n",
       "      <td>InTheMood</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>This is by far the worst Pokémon game I have e...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2893</td>\n",
       "      <td>Dreadwolf85</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>Lazy game design. Pokemon still dont hit each ...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2897</td>\n",
       "      <td>Cotroneo</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>If you consider this game a successor to the s...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2901</td>\n",
       "      <td>Guandaside</td>\n",
       "      <td>Nov 21, 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>The game is good overall, but there are two ma...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1231 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name          date  rating  \\\n",
       "0      ChocolateCrane  Nov 18, 2019       4   \n",
       "3     firstlovezombie  Nov 15, 2019       2   \n",
       "4        FilthyActs88  Nov 15, 2019       1   \n",
       "5          Ninjasuite  Nov 15, 2019       3   \n",
       "6        JustrzBustrz  Nov 15, 2019       2   \n",
       "...               ...           ...     ...   \n",
       "2889           Gonz04  Nov 20, 2019       0   \n",
       "2891        InTheMood  Nov 20, 2019       1   \n",
       "2893      Dreadwolf85  Nov 20, 2019       3   \n",
       "2897         Cotroneo  Nov 20, 2019       2   \n",
       "2901       Guandaside  Nov 21, 2019       0   \n",
       "\n",
       "                                                 review    game sentiment  \n",
       "0     Let us address the elephant in the room first....   sword  negative  \n",
       "3     I really love Pokemon, which is why I'm so cri...   sword  negative  \n",
       "4     Pokémon sword and shield is a game of pure med...   sword  negative  \n",
       "5     This is what happen if a company realize that ...   sword  negative  \n",
       "6     It’s an amazing feat how soulless this game fe...   sword  negative  \n",
       "...                                                 ...     ...       ...  \n",
       "2889  This game is so disappointing, I literally end...  shield  negative  \n",
       "2891  This is by far the worst Pokémon game I have e...  shield  negative  \n",
       "2893  Lazy game design. Pokemon still dont hit each ...  shield  negative  \n",
       "2897  If you consider this game a successor to the s...  shield  negative  \n",
       "2901  The game is good overall, but there are two ma...  shield  negative  \n",
       "\n",
       "[1231 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = negative['review'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['let', 'us', 'address', 'the', 'elephant', 'in', 'the', 'room', 'first', 'the', 'absence', 'of', 'the', 'national', 'dex', 'yes', 'it', 'is', 'terrible', 'lazy', 'blah', 'blah', 'blah', 'am', 'sure', 'you', 've', 'already', 'heard', 'this', 'in', 'hundreds', 'of', 'other', 'reviews', 'so', 'instead', 'of', 'me', 'wasting', 'your', 'time', 'by', 'complaining', 'about', 'something', 'you', 'are', 'already', 'well', 'aware', 'of', 'will', 'focus', 'on', 'the', 'rest', 'of', 'swsh', 'shortcomings', 'for', 'reference', 'have', 'played', 'every', 'mainline', 'pokemon', 'game', 'to', 'completion', 'and', 'have', 'currently', 'sunk', 'hours', 'into', 'shield', 'imagine', 'my', 'criticisms', 'also', 'apply', 'to', 'sword', 'in', 'the', 'interest', 'of', 'brevity', 'will', 'be', 'utilizing', 'acronyms', 'swsh', 'sword', 'shield', 'sun', 'moon', 'etc', 'the', 'most', 'succinct', 'way', 'to', 'put', 'it', 'is', 'swsh', 'essentially', 'feels', 'like', 'ds', 'game', 'ported', 'to', 'the', 'switch', 'this', 'applies', 'to', 'every', 'facet', 'of', 'the', 'game', 'from', 'its', 'gameplay', 'features', 'to', 'its', 'visual', 'presentation', 'to', 'its', 'story', 'characters', 'believe', 'whether', 'or', 'not', 'you', 'enjoy', 'swsh', 'depends', 'entirely', 'upon', 'how', 'you', 'view', 'the', 'th', 'gen', 'games', 'contrary', 'to', 'what', 'the', 'devs', 'promised', 'us', 'last', 'year', 'swsh', 'is', 'most', 'assuredly', 'not', 'meant', 'for', 'the', 'core', 'pokemon', 'fans', 'as', 'veteran', 'of', 'the', 'series', 'myself', 'can', 'say', 'with', 'certainty', 'the', 'abysmally', 'low', 'level', 'of', 'difficulty', 'in', 'conjunction', 'with', 'the', 'simplification', 'and', 'outright', 'removal', 'of', 'many', 'features', 'is', 'the', 'exact', 'opposite', 'of', 'what', 'want', 'swsh', 'is', 'nearly', 'as', 'simplified', 'as', 'lgpe', 'which', 'wouldn', 'be', 'an', 'issue', 'if', 'the', 'devs', 'addressed', 'it', 'as', 'such', 'but', 'somehow', 'they', 'seem', 'to', 'think', 'this', 'is', 'what', 'qualifies', 'as', 'satisfying', 'mainline', 'game', 'in', 'yes', 'pokemon', 'has', 'always', 'been', 'franchise', 'aimed', 'primarily', 'at', 'children', 'the', 'games', 'have', 'never', 'been', 'truly', 'difficult', 'when', 'compared', 'to', 'many', 'of', 'their', 'jrpg', 'contemporaries', 'yet', 'for', 'some', 'reason', 'game', 'freak', 'felt', 'the', 'need', 'to', 'crank', 'that', 'difficulty', 'setting', 'from', 'easy', 'down', 'to', 'braindead', 'may', 'have', 'been', 'easy', 'but', 'it', 'was', 'leagues', 'more', 'challenging', 'than', 'shield', 'accessibility', 'is', 'one', 'thing', 'but', 'this', 'is', 'taking', 'it', 'to', 'such', 'an', 'extreme', 'it', 'nearly', 'removes', 'all', 'the', 'fun', 'hard', 'mode', 'option', 'selectable', 'from', 'the', 'outset', 'would', 'have', 'worked', 'wonders', 'and', 'of', 'course', 'as', 'is', 'common', 'for', 'the', 'past', 'several', 'entries', 'in', 'the', 'pokemon', 'series', 'the', 'post', 'game', 'content', 'is', 'practically', 'non', 'existent', 'so', 'swsh', 'basically', 'fails', 'when', 'viewed', 'purely', 'as', 'game', 'but', 'what', 'of', 'the', 'other', 'aspects', 'mentioned', 'after', 'all', 'jrpgs', 'with', 'subpar', 'gameplay', 'can', 'still', 'be', 'surprisingly', 'enjoyable', 'if', 'the', 'narrative', 'holds', 'enough', 'merit', 'am', 'sad', 'to', 'report', 'that', 'swsh', 'also', 'completely', 'fails', 'in', 'this', 'regard', 'the', 'writing', 'is', 'oftentimes', 'so', 'atrocious', 've', 'found', 'myself', 'wishing', 'to', 'skip', 'these', 'scenes', 'entirely', 'this', 'is', 'par', 'for', 'the', 'course', 'as', 'none', 'of', 'the', 'mainline', 'games', 'barring', 'the', 'attempts', 'made', 'in', 'have', 'really', 'delivered', 'anything', 'substantive', 'in', 'the', 'way', 'of', 'competent', 'storytelling', 'however', 'with', 'the', 'majority', 'of', 'other', 'pokemon', 'games', 'they', 'at', 'least', 'had', 'good', 'gameplay', 'to', 'compensate', 'for', 'the', 'lackluster', 'story', 'factor', 'which', 'is', 'completely', 'absent', 'from', 'swsh', 'due', 'to', 'its', 'inherent', 'simplified', 'nature', 'and', 'toddler', 'pandering', 'difficulty', 'well', 'there', 'is', 'only', 'one', 'thing', 'left', 'to', 'discuss', 'since', 'delving', 'into', 'too', 'much', 'detail', 'on', 'the', 'above', 'points', 'causes', 'me', 'to', 'exceed', 'the', 'character', 'limit', 'the', 'final', 'point', 'of', 'contention', 'is', 'the', 'visual', 'fidelity', 'and', 'graphical', 'offerings', 'swsh', 'brings', 'to', 'the', 'table', 'this', 'is', 'after', 'all', 'game', 'made', 'for', 'the', 'switch', 'console', 'handheld', 'hybrid', 'with', 'roughly', 'the', 'computational', 'power', 'of', 'pokemon', 'former', 'home', 'the', 'ds', 'let', 'get', 'the', 'pesky', 'numbers', 'out', 'of', 'the', 'way', 'first', 'swsh', 'runs', 'at', 'dynamic', 'resolution', 'on', 'both', 'docked', 'and', 'portable', 'modes', 'in', 'docked', 'mode', 'the', 'resolution', 'fluctuates', 'from', 'to', 'likewise', 'during', 'portable', 'play', 'the', 'highest', 'res', 'is', 'which', 'descends', 'to', 'on', 'frequent', 'occasions', 'this', 'is', 'somewhat', 'disappointing', 'considering', 'lgpe', 'was', 'capable', 'of', 'running', 'at', 'docked', 'portable', 'at', 'all', 'times', 'the', 'framerate', 'target', 'is', 'fps', 'which', 'exhibits', 'frame', 'pacing', 'problems', 'and', 'severe', 'drops', 'in', 'variety', 'of', 'areas', 'the', 'most', 'evident', 'manifestation', 'of', 'these', 'issues', 'can', 'be', 'seen', 'in', 'the', 'wild', 'area', 'wherein', 'both', 'pacing', 'and', 'framerate', 'are', 'pushed', 'to', 'their', 'absolute', 'worst', 'this', 'is', 'massive', 'problem', 'considering', 'the', 'majority', 'of', 'your', 'time', 'especially', 'in', 'post', 'game', 'will', 'likely', 'be', 'spent', 'in', 'the', 'wild', 'area', 'aside', 'from', 'the', 'quantifiable', 'metrics', 'highlighted', 'above', 'there', 'are', 'plenty', 'of', 'other', 'visual', 'shortcomings', 'to', 'boot', 'terrible', 'terrain', 'detail', 'awful', 'textures', 'constant', 'pop', 'in', 'stilted', 'animations', 'low', 'polygon', 'count', 'for', 'both', 'the', 'human', 'character', 'models', 'as', 'well', 'as', 'the', 'pokemon', 'and', 'countless', 'other', 'issues', 'such', 'as', 'these', 'result', 'in', 'game', 'that', 'resembles', 'something', 'released', 'over', 'decade', 'ago', 'many', 'detractors', 'claim', 'swsh', 'looks', 'like', 'ps', 'gc', 'game', 'which', 'is', 'definitely', 'an', 'exaggeration', 'but', 'what', 'we', 'got', 'is', 'by', 'no', 'means', 'acceptable', 'for', 'non', 'indie', 'game', 'released', 'in', 'and', 'yes', 'many', 'of', 'the', 'animations', 'and', 'all', 'the', 'returning', 'pokemon', 'models', 'have', 'been', 'copy', 'and', 'pasted', 'with', 'negligible', 'improvements', 'for', 'swsh', 'it', 'one', 'thing', 'to', 'sacrifice', 'content', 'for', 'more', 'polished', 'higher', 'quality', 'game', 'but', 'that', 'is', 'very', 'clearly', 'not', 'what', 'happened', 'here', 'genuinely', 'hope', 'these', 'issues', 'can', 'be', 'sorted', 'out', 'in', 'future', 'releases', 'am', 'not', 'ready', 'to', 'give', 'up', 'hope', 'on', 'pokemon', 'just', 'yet']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models - reference: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=3) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=3)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pokemon_sword_and_shield', 'boast', 'expansive', 'landscapes', 'and', 'sense_of', 'ambition', 'at_first', 'the', 'more', 'the_game', 'goes_on', 'you', 'become', 'aware', 'of', 'how', 'hastily', 'put', 'together', 'and', 'hollow', 'it', 'really', 'is', 'the_main', 'selling_point', 'the_wild_area_is', 'smaller_than', 'you_would_expect', 'and', 'plain', 'ugly', 'to', 'boot', 'there_is', 'not', 'lot', 'to_do', 'there', 'the_same', 'games', 'for', 'the_game', 'traditional', 'routes', 'which_are', 'some_of_the', 'smallest', 'and', 'most', 'linear', 'yet', 'this', 'combined', 'with', 'the_game', 'interrupting', 'you', 'every', 'seconds', 'for', 'leon', 'to', 'brag', 'about', 'his', 'charizard', 'or', 'whatever', 'make', 'the_game', 'chore', 'to', 'sit', 'through', 'despite', 'their', 'short', 'length', 'that', 'not', 'to_say', 'the_game', 'doesn', 'have', 'it', 'positives', 'though', 'galar', 'can_be', 'quite', 'pretty', 'when_it_comes_to', 'towns', 'and', 'colors', 'and', 'there_are_some', 'much', 'welcome', 'quality_of_life_improvements', 'like', 'easily', 'accessible', 'move', 're', 'learners', 'and', 'nature', 'mints', 'lot_of', 'the_series', 'past', 'tedium', 'is', 'now', 'gone', 'and', 'getting', 'into', 'competitive', 'has', 'never_been', 'easier', 'the_new', 'monster', 'designs', 'themselves_are', 'also', 'cool', 'and', 'imaginative', 'the', 'dynamax', 'gym_battle', 'are', 'sight', 'to', 'behold', 'with', 'their', 'giant', 'battles', 'and', 'roaring', 'crowds', 'also', 'much', 'prefer', 'the_new', 'comm', 'to', 'generation', 'festival', 'plaza', 'unfortunately', 'that', 'about', 'all', 'nice', 'have_to_say', 'about', 'the', 'games', 'the', 'difficulty', 'is_nonexistent', 'the_story_is', 'dull', 'and', 'predictable', 'and', 'the', 'overall', 'content', 'and', 'variety', 'pales', 'compared_to', 'past', 'entries', 'despite', 'them', 'sacrificing', 'pokemon', 'and', 'costing', 'more', 'these', 'negatives', 'as_well_as', 'the', 'technical_issues', 'and', 'signs', 'of', 'rushed', 'game', 'an', 'important', 'battle', 'has_no', 'music', 'last', 'gym', 'is', 'single', 'room', 'etc', 'mean', 'can_only', 'give', 'these', 'there_is', 'potential_but', 'they_need_to', 'spend', 'more_time', 'on', 'their', 'products', 'for', 'something', 'truly', 'good', 'better', 'luck', 'next', 'game']\n"
     ]
    }
   ],
   "source": [
    "print(trigram_mod[bigram_mod[data_words[7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a26bf9d133db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Do lemmatization keeping only noun, adj, vb, adv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata_lemmatized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_words_bigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VERB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-a9dac53f8cd2>\u001b[0m in \u001b[0;36mlemmatization\u001b[0;34m(texts, allowed_postags)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtexts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtexts_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.set_annotations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag_id\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.lemmatize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/spacy/lemmatizer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string, univ_pos, morphology)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mindex_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniv_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mexc_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniv_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mrules_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniv_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         )\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlemmas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/spacy/lemmatizer.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, string, index, exceptions, rules)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.010*\"bad\" + 0.010*\"animation\" + 0.008*\"game\" + 0.008*\"graphic\" + '\n",
      "  '0.007*\"get\" + 0.007*\"good\" + 0.007*\"even\" + 0.006*\"make\" + 0.006*\"cut\" + '\n",
      "  '0.006*\"move\"'),\n",
      " (1,\n",
      "  '0.010*\"bad\" + 0.009*\"make\" + 0.008*\"animation\" + 0.008*\"game\" + 0.007*\"go\" '\n",
      "  '+ 0.006*\"look\" + 0.006*\"battle\" + 0.006*\"also\" + 0.006*\"new\" + '\n",
      "  '0.005*\"play\"'),\n",
      " (2,\n",
      "  '0.014*\"game\" + 0.012*\"make\" + 0.011*\"bad\" + 0.009*\"even\" + '\n",
      "  '0.007*\"animation\" + 0.007*\"new\" + 0.007*\"story\" + 0.006*\"would\" + '\n",
      "  '0.006*\"graphic\" + 0.006*\"feel\"'),\n",
      " (3,\n",
      "  '0.016*\"game\" + 0.012*\"make\" + 0.010*\"even\" + 0.009*\"new\" + 0.008*\"cut\" + '\n",
      "  '0.008*\"animation\" + 0.008*\"play\" + 0.007*\"really\" + 0.007*\"good\" + '\n",
      "  '0.007*\"bad\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
