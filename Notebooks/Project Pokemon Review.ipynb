{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import re \n",
    "import string \n",
    "\n",
    "import nltk\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening Scrapped Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pokemon.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2903 entries, 0 to 887\n",
      "Data columns (total 5 columns):\n",
      "name      2903 non-null object\n",
      "date      2903 non-null object\n",
      "rating    2903 non-null object\n",
      "review    2903 non-null object\n",
      "game      2903 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 136.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's group the reviews by their ratings \n",
    "### following metacritics, 0 to 4 = negative, 5 to 7 mixed, 8 and above = positive \n",
    "\n",
    "def sentiment(x):\n",
    "    if x > 7:\n",
    "        return 'positive'\n",
    "    if x < 5:\n",
    "        return 'negative'\n",
    "    else: return 'mixed'\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(lambda x:sentiment(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.610059\n",
       "positive    0.306235\n",
       "mixed       0.083707\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metagrass</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>I have also done a review for Pokemon Sword, b...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NintendoGuy64</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>As a lifelong fan of Pokemon games, I was ecst...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Otonaburu</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>What should have been a giant leap to signific...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gamermangamer</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Was promised a game for \"long time fans of the...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fumetic</td>\n",
       "      <td>Nov 15, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>As these are largely the same games, I have pa...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>HollyS</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>Very short, bland and low quality Pokemon game...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Lawrence7</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>10</td>\n",
       "      <td>For anyone debating whether they will like the...</td>\n",
       "      <td>shield</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>sojasonk</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Lazy writing, bad graphics, an absolute medioc...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>KrakenOfPepsi</td>\n",
       "      <td>Nov 20, 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>Metacritic has a pretty small character limit ...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Mack_thge_Sack</td>\n",
       "      <td>Nov 21, 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm going to state my points and not my emotio...</td>\n",
       "      <td>shield</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name          date  rating  \\\n",
       "0         Metagrass  Nov 15, 2019       2   \n",
       "1     NintendoGuy64  Nov 15, 2019       0   \n",
       "4         Otonaburu  Nov 15, 2019       4   \n",
       "7     Gamermangamer  Nov 15, 2019       1   \n",
       "8           Fumetic  Nov 15, 2019       3   \n",
       "..              ...           ...     ...   \n",
       "871          HollyS  Nov 20, 2019       2   \n",
       "875       Lawrence7  Nov 20, 2019      10   \n",
       "877        sojasonk  Nov 20, 2019       1   \n",
       "879   KrakenOfPepsi  Nov 20, 2019       4   \n",
       "887  Mack_thge_Sack  Nov 21, 2019       0   \n",
       "\n",
       "                                                review    game sentiment  \n",
       "0    I have also done a review for Pokemon Sword, b...  shield  negative  \n",
       "1    As a lifelong fan of Pokemon games, I was ecst...  shield  negative  \n",
       "4    What should have been a giant leap to signific...  shield  negative  \n",
       "7    Was promised a game for \"long time fans of the...  shield  negative  \n",
       "8    As these are largely the same games, I have pa...  shield  negative  \n",
       "..                                                 ...     ...       ...  \n",
       "871  Very short, bland and low quality Pokemon game...  shield  negative  \n",
       "875  For anyone debating whether they will like the...  shield  positive  \n",
       "877  Lazy writing, bad graphics, an absolute medioc...  shield  negative  \n",
       "879  Metacritic has a pretty small character limit ...  shield  negative  \n",
       "887  I'm going to state my points and not my emotio...  shield  negative  \n",
       "\n",
       "[427 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Some users posted on both pokemon sword and shield. \n",
    "### Did some checks, these reviews were the same  \n",
    "\n",
    "df[df.duplicated('name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313    I'm going to state my points and not my emotio...\n",
       "887     I'm going to state my points and not my emotio...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[df['name'] == 'Mack_thge_Sack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping duplicate names \n",
    "df.drop_duplicates(subset='name', keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### detect review language and returns NaN if not english \n",
    "def language_detection(x): \n",
    "    result = detect(x)\n",
    "    if result == 'en':\n",
    "        return x \n",
    "    else: return np.NaN \n",
    "    \n",
    "df['review'] = df['review'].apply(lambda x:language_detection(x))\n",
    "\n",
    "### drop reviews that are not in english \n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_r(x):\n",
    "    return x.replace('\\r','')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:remove_r(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_whitespace(x):\n",
    "    return x.strip()\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:strip_whitespace(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub('\\d', '', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub('[%s]' % re.escape(string.punctuation), '', text) \n",
    "\n",
    "#df['review'] = df['review'].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = make_lower(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_digits(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['review'] = df['review'].apply(lambda x:remove_stopwords(str.split(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "# def lemmatize_words(x):\n",
    "#     lemmed_string = ''\n",
    "#     for word in x.split():\n",
    "#         lemmed_string = lemmed_string+' '+lemmatizer.lemmatize(word)  \n",
    "#     return lemmed_string.lstrip()\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_words(x):\n",
    "    text = sp(x)\n",
    "    lemmed_string =''\n",
    "    for word in text:\n",
    "        if word.lemma_ == '-PRON-':\n",
    "            word.lemma_ = word.orth_ # change the string representation\n",
    "            word.lemma = word.orth #\n",
    "        else: lemmed_string = lemmed_string+' '+word.lemma_\n",
    "    return lemmed_string.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models - reference: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "data = []\n",
    "for entry in df.review:\n",
    "    data.append(entry.split())\n",
    "\n",
    "bigram = gensim.models.Phrases(data, min_count=5, threshold=5) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data], threshold=5)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def make_bigrams(x):\n",
    "    text = bigram_mod[x.split()] \n",
    "    grammed_string = ''\n",
    "    for word in text: \n",
    "        grammed_string = grammed_string+' '+word \n",
    "    return grammed_string \n",
    "\n",
    "def make_trigrams(x):\n",
    "    text = trigram_mod[bigram_mod[x.split()] ] \n",
    "    grammed_string = ''\n",
    "    for word in text: \n",
    "        grammed_string = grammed_string+' '+word \n",
    "    return grammed_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x:make_bigrams(x))  \n",
    "df['review'] = df['review'].apply(lambda x:make_trigrams(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### create list of rare words by filtering on word counts\n",
    "freq = pd.DataFrame(df.review.str.split(expand=True).stack().value_counts())\n",
    "freq = freq[freq<10]\n",
    "freq.dropna(inplace = True)\n",
    "freq.reset_index(inplace = True)\n",
    "freq = freq['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare(x):\n",
    "    for word in freq:\n",
    "        if word in x:\n",
    "            return x.replace(word,'')   \n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:remove_rare(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dfclean.pickle')\n",
    "\n",
    "# with open('dfclean.pickle','rb') as read_file:\n",
    "#      df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq = pd.DataFrame(df.review.str.split(expand=True).stack().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove stopwords text, using this method just incase I want to add more stopwords \n",
    "nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words =  list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "stop_words.extend(['game','pokemon','pokÃ©mon','battle','animation','good','bad'])\n",
    "\n",
    "for word in stop_words:\n",
    "    if word in stop_words: \n",
    "        continue\n",
    "    else: stop_words.append(word)\n",
    "\n",
    "for word in stop_words:\n",
    "    no_punct = remove_punctuation(word)\n",
    "    if no_punct not in stop_words: \n",
    "        stop_words.append(no_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting df by sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = df[df['sentiment']=='negative']\n",
    "mixed = df[df['sentiment']=='mixed']\n",
    "positive = df[df['sentiment']=='postive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words,\n",
    "                                   strip_accents = 'ascii', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z][a-z]+\\\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word = vectorizer.fit_transform(negative.review)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(doc_word.toarray(), index=negative.review, columns=vectorizer.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(5)\n",
    "doc_topic = lsa.fit_transform(doc_word)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(lsa.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lsa, vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(negative.review)\n",
    "doc_word = vectorizer.transform(negative.review).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda = models.LdaModel(corpus=corpus, num_topics=3, id2word=id2word, passes=20)\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=50,\n",
    "                                           passes=20,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
